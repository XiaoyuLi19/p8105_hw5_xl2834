---
title: "p8105_hw5_xl2834"
author: "Xiaoyu Li"
date: "11/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .6,
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```




## Problem 2

```{r}
file_path = 
  list.files(path = "./data/hw5_data/data", full.names = TRUE)



read_data = function(x) {
  
  study_df = read_csv(x) %>% 
             mutate(arm_id = str_sub(x, start = -10, end = -5))
  
  study_df
}

output_1 = vector("list", length = 10)

for (i in 1:10) {
  output_1[[i]] = read_data(file_path[[i]])
}

```


use map

```{r}
output_1 = map(file_path, read_data)

study_result = 
  bind_rows(output_1) %>% 
  separate(arm_id, into = c("arm","id"), sep = "_") %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation") %>% 
  mutate(week = str_sub(week, -1))
```

```{r}
study_result %>% 
  ggplot(aes(x = week, y = observation, group = id, color = arm)) + 
  geom_line() +
  facet_grid(. ~ arm)
```

In the control group, the observation value did not change much across weeks. In the experiment group, the observation values increase over the weeks.

# Problem 3

```{r}
sim_mean_p = function(n = 30, mu = 0, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data %>% 
    summarize(
      mu_hat = mean(x),
      p_value = broom::tidy(t.test(x, mu = 0))$p.value
    )
}


sim_results = 
  rerun(5000, sim_mean_p(30, 0, 5)) %>% 
  bind_rows()
```

Repeat for mu = 0 to 6

```{r}
mu_list = 
  list(
    "mu_1" = 0,
    "mu_2" = 1, 
    "mu_3" = 2, 
    "mu_4" = 3, 
    "mu_5" = 4,
    "mu_6" = 5,
    "mu_7" = 6
    )

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(5000, sim_mean_p(mu = mu_list[[i]])) %>% 
    bind_rows
}
```

Build a dataset

```{r}
result_df =
  tibble(
  mu = c(0, 1, 2, 3, 4, 5, 6)
) %>% 
  mutate(
    output_lists = map(.x = mu, ~ rerun(5000, sim_mean_p(mu = .x))),
    estimate_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_df)
```


Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

```{r}
reject_df = 
  result_df %>% 
  mutate(
    reject_null = case_when(
      p_value < 0.05 ~ "rejected",
      p_value >= 0.05 ~ "failed to reject"
    )
  ) %>% 
  select(mu, reject_null) %>% 
  group_by(mu) %>% 
  summarize(
    reject_total = sum(reject_null == "rejected")
  ) %>% 
  mutate(reject_proportion = reject_total / 5000)

reject_df %>% 
  ggplot(aes(x = mu, y = reject_proportion)) +
  geom_point() 

```

The higher the mu value, the higher the proporiton of times that null is rejected. This indicates that a larger effect size can lead to higher power.


Make a plot showing the average estimate of μ hat on the y axis and the true value of μ on the x axis.
```{r}
plot_2 =
  result_df %>% 
  group_by(mu) %>% 
  summarize(avg_mu_hat = mean(mu_hat)) %>% 
  ggplot(aes(x = mu, y = avg_mu_hat)) +
  geom_point() +
  
  labs(
    title = "mean mu hat in groups with different mu")

```

Make a second plot (or overlay on the first) the average estimate of μ hat only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.
```{r}
plot_3 = 
  result_df %>% 
  mutate(
    reject_null = case_when(
      p_value < 0.05 ~ "rejected",
      p_value >= 0.05 ~ "failed to reject"
    )
  ) %>%
  filter(reject_null == "rejected") %>% 
  group_by(mu) %>% 
  summarize(mean_mu_hat = mean(mu_hat)) %>% 
  ggplot(aes(x = mu, y = mean_mu_hat)) +
  geom_point() +
  labs(
    title = "mean mu hat in samples where null was rejected")
  
```

```{r}
plot_2 + plot_3
```

With the increase of μ, the effect size increases, and power increases.
The sample average of μ hat across tests for which the null is rejected approximately equal to the true value of μ when μ = 0, 4, 5, 6, and is not approximately equal when μ = 1, 2, 3. When μ = 0, the sample with rejected null lie in both tails of the distribution (both positive side and negative side), so the average of the sample is close to 0. When μ = 1, 2, 3, the sample with rejected null lie primarily in the upper tail, so the average is larger than the true value of μ. When μ = 4,5,6, almost all samples have rejected null, so the average is close to true value of μ. 